{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.__version__)  # Check if pandas is correctly installed and shows the version\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet Names: ['Sheet1', 'Sheet2']\n",
      "\n",
      "Sheet 1 Content:\n",
      "     Name  Age  Subject\n",
      "0     Ali   25     Math\n",
      "1    Sara   23  English\n",
      "2  Kamran   35  History\n",
      "3    Amir   29  Science\n",
      "4  Fatima   22     Math\n",
      "\n",
      "Sheet 2 Content:\n",
      "    ID  Salary Department\n",
      "0  101   30000         HR\n",
      "1  102   40000    Finance\n",
      "2  103   50000         IT\n",
      "3  104   60000  Marketing\n",
      "4  105   70000      Sales\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'C:/Users/dell/Downloads/sample_data.xlsx'\n",
    "try:\n",
    "    # Load the Excel file\n",
    "    excel_file = pd.ExcelFile(file_path)\n",
    "    # Print sheet names\n",
    "    print(\"Sheet Names:\", excel_file.sheet_names)\n",
    "    # Parse and print both sheets\n",
    "    sheet1 = excel_file.parse('Sheet1')\n",
    "    sheet2 = excel_file.parse('Sheet2')\n",
    "    print(\"\\nSheet 1 Content:\")\n",
    "    print(sheet1)\n",
    "    print(\"\\nSheet 2 Content:\")\n",
    "    print(sheet2)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file {file_path} was not found. Please check the path.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error: {e}. Try installing missing dependencies with:\\n\"\n",
    "          \"python -m pip install openpyxl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame for Task 2:\n",
      "        Math  Science  English  History\n",
      "Ali       85       80       88       75\n",
      "Amir      90       95       76       85\n",
      "Kamran    78       89       90       89\n",
      "Sara      92       85       94       78\n",
      "Fatima    88       87       91       80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {\n",
    "    'Math': [85, 90, 78, 92, 88],\n",
    "    'Science': [80, 95, 89, 85, 87],\n",
    "    'English': [88, 76, 90, 94, 91],\n",
    "    'History': [75, 85, 89, 78, 80]\n",
    "}\n",
    "df = pd.DataFrame(data, index=['Ali', 'Amir', 'Kamran', 'Sara', 'Fatima'])\n",
    "# Print the DataFrame\n",
    "print(\"DataFrame for Task 2:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two columns from Sheet1:\n",
      "     Name  Age\n",
      "0     Ali   25\n",
      "1    Sara   23\n",
      "2  Kamran   35\n",
      "3    Amir   29\n",
      "4  Fatima   22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'C:/Users/dell/Downloads/sample_data.xlsx'\n",
    "df = pd.read_excel(file_path, usecols=[0, 1], sheet_name='Sheet1')\n",
    "print(\"First two columns from Sheet1:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after skipping the first two rows:\n",
      "     Sara  23  English\n",
      "0  Kamran  35  History\n",
      "1    Amir  29  Science\n",
      "2  Fatima  22     Math\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = 'C:/Users/dell/Downloads/sample_data.xlsx'\n",
    "df = pd.read_excel(file_path, skiprows=2, sheet_name='Sheet1')\n",
    "print(\"Data after skipping the first two rows:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows 10 to 30 after filling missing values:\n",
      "    ID    Name     Gender  Age\n",
      "10  11   Ahsan       Male   29\n",
      "11  12    Zain  No Gender   34\n",
      "12  13    Saad       Male   31\n",
      "13  14    Hina     Female   23\n",
      "14  15    Sana     Female   25\n",
      "15  16   Bilal  No Gender   32\n",
      "16  17   Adeel       Male   28\n",
      "17  18    Iqra     Female   22\n",
      "18  19  Areeba     Female   24\n",
      "19  20  Junaid  No Gender   29\n",
      "20  21    Anam  No Gender   30\n",
      "21  22   Rehan       Male   35\n",
      "22  23    Taha       Male   27\n",
      "23  24   Lubna     Female   26\n",
      "24  25    Raza       Male   34\n",
      "25  26  Farooq  No Gender   31\n",
      "26  27   Owais       Male   33\n",
      "27  28  Danish       Male   28\n",
      "28  29   Rabia     Female   22\n",
      "29  30    Aqsa     Female   21\n",
      "Total number of rows: 35\n",
      "First few rows:\n",
      "   ID    Name     Gender  Age\n",
      "0   1     Ali       Male   25\n",
      "1   2    Sara     Female   22\n",
      "2   3  Kamran  No Gender   30\n",
      "3   4    Amir       Male   28\n",
      "4   5  Fatima     Female   21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_path = './employees_extended.xlsx' \n",
    "df = pd.read_excel(file_path)\n",
    "df = df.assign(Gender=df['Gender'].fillna('No Gender'))\n",
    "print(\"Rows 10 to 30 after filling missing values:\")\n",
    "print(df.iloc[10:30])\n",
    "print(f\"Total number of rows: {len(df)}\")\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Age  Salary\n",
      "0   25   30000\n",
      "1   30   35000\n",
      "2   35   40000\n",
      "3   40   45000\n",
      "4   45   50000\n",
      "5   50   55000\n",
      "6   55   60000\n",
      "7   60   65000\n",
      "8   65   70000\n",
      "9   70   75000\n",
      "\n",
      "Normalized Data:\n",
      "        Age    Salary\n",
      "0  0.000000  0.000000\n",
      "1  0.111111  0.111111\n",
      "2  0.222222  0.222222\n",
      "3  0.333333  0.333333\n",
      "4  0.444444  0.444444\n",
      "5  0.555556  0.555556\n",
      "6  0.666667  0.666667\n",
      "7  0.777778  0.777778\n",
      "8  0.888889  0.888889\n",
      "9  1.000000  1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'Salary': [30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df)\n",
    "df_normalized = pd.DataFrame(normalized_data, columns=df.columns)\n",
    "print(\"\\nNormalized Data:\")\n",
    "print(df_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Age  Salary\n",
      "0   25   30000\n",
      "1   30   35000\n",
      "2   35   40000\n",
      "3   40   45000\n",
      "4   45   50000\n",
      "5   50   55000\n",
      "6   55   60000\n",
      "7   60   65000\n",
      "8   65   70000\n",
      "9   70   75000\n",
      "\n",
      "Standardized Data:\n",
      "        Age    Salary\n",
      "0 -1.566699 -1.566699\n",
      "1 -1.218544 -1.218544\n",
      "2 -0.870388 -0.870388\n",
      "3 -0.522233 -0.522233\n",
      "4 -0.174078 -0.174078\n",
      "5  0.174078  0.174078\n",
      "6  0.522233  0.522233\n",
      "7  0.870388  0.870388\n",
      "8  1.218544  1.218544\n",
      "9  1.566699  1.566699\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample dataset with Age and Salary columns\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'Salary': [30000, 35000, 40000, 45000, 50000, 55000, 60000, 65000, 70000, 75000]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Apply StandardScaler for standardization\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(df)\n",
    "\n",
    "# Create a DataFrame for standardized values\n",
    "df_standardized = pd.DataFrame(standardized_data, columns=df.columns)\n",
    "\n",
    "print(\"\\nStandardized Data:\")\n",
    "print(df_standardized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   First Score  Second Score  Third Score\n",
      "0        100.0          30.0          NaN\n",
      "1         90.0          45.0         40.0\n",
      "2          NaN          56.0         80.0\n",
      "3         95.0           NaN         98.0\n",
      "\n",
      "Data After Backward Interpolation:\n",
      "   First Score  Second Score  Third Score\n",
      "0        100.0          30.0         40.0\n",
      "1         90.0          45.0         40.0\n",
      "2         92.5          56.0         80.0\n",
      "3         95.0           NaN         98.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Given dictionary\n",
    "data = {\n",
    "    'First Score': [100, 90, np.nan, 95],\n",
    "    'Second Score': [30, 45, 56, np.nan],\n",
    "    'Third Score': [np.nan, 40, 80, 98]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Apply backward interpolation\n",
    "df_interpolated = df.interpolate(method='linear', limit_direction='backward')\n",
    "\n",
    "print(\"\\nData After Backward Interpolation:\")\n",
    "print(df_interpolated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   userId  movieId  rating            timestamp\n",
      "0       1        2     3.5  2005-04-02 23:53:47\n",
      "1       1       29     3.5  2005-04-02 23:31:16\n",
      "2       1       32     3.5  2005-04-02 23:33:39\n",
      "3       1       47     3.5  2005-04-02 23:32:07\n",
      "4       1       50     3.5  2005-04-02 23:29:40\n",
      "\n",
      "Missing Values in the Dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provide the correct path to the dataset (adjust path if needed)\n",
    "file_path = \"../../../Kaggle-Datasets/MovieLens/rating.csv\"\n",
    "\n",
    "# Load the ratings dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values in the Dataset:\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset after filling missing values:\n",
      "   userId  movieId  rating            timestamp\n",
      "0       1        2     3.5  2005-04-02 23:53:47\n",
      "1       1       29     3.5  2005-04-02 23:31:16\n",
      "2       1       32     3.5  2005-04-02 23:33:39\n",
      "3       1       47     3.5  2005-04-02 23:32:07\n",
      "4       1       50     3.5  2005-04-02 23:29:40\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Provide the correct path to the dataset (adjust path if needed)\n",
    "file_path = \"../../../Kaggle-Datasets/MovieLens/rating.csv\"\n",
    "\n",
    "# Load the ratings dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Fill missing values (if any) with 0\n",
    "df_filled = df.fillna(0)\n",
    "\n",
    "print(\"Dataset after filling missing values:\")\n",
    "print(df_filled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
